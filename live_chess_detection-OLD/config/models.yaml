# Model Architectures Configuration

# Piece Classifier (for synthetic and digital boards)
piece_classifier:
  architecture: alexnet_variant
  input_channels: 3
  num_classes: 13  # 12 pieces + empty square
  dropout: 0.5
  
  # Layer configuration
  conv_layers:
    - {filters: 64, kernel: 7, stride: 2, padding: 2}  # Initial feature extraction
    - {filters: 192, kernel: 5, padding: 2}
    - {filters: 384, kernel: 3, padding: 1}
    - {filters: 256, kernel: 3, padding: 1}
    - {filters: 256, kernel: 3, padding: 1}
  
  fc_layers:
    - 4096
    - 2048
    - 13  # Output classes
  
  pooling:
    type: MaxPool2d
    kernel: 3
    stride: 2
  
  activation: ReLU
  batch_norm: true

# YOLO Detector
yolo_detector:
  base_model: yolov8s  # Options: yolov8n, yolov8s, yolov8m, yolov8l, yolov8x
  pretrained: true
  freeze_backbone: false  # Fine-tune entire model
  
  # Model parameters
  input_size: [1024, 1024]
  conf_threshold: 0.45  # Tuned empirically (tested 0.3, 0.4, 0.45, 0.5)
  iou_threshold: 0.45
  max_det: 64  # Max detections per image (8x8 board = 32 pieces max)
  
  # Training augmentation
  augmentation:
    hsv_h: 0.015  # Hue variation
    hsv_s: 0.7    # Saturation
    hsv_v: 0.4    # Value
    degrees: 5.0   # Rotation range
    translate: 0.1 # Translation
    scale: 0.2     # Scaling
    shear: 0.0     # No shearing (board should be rectangular)
    perspective: 0.0  # No perspective (already top-down)
    flipud: 0.0    # Don't flip vertically
    fliplr: 0.5    # Flip horizontally 50%
    mosaic: 0.8    # Mosaic augmentation probability
    mixup: 0.1     # Mixup probability
  
  # Classes (ordered as in training)
  classes:
    0: "0"   # Empty square
    1: "B"   # White Bishop
    2: "K"   # White King
    3: "N"   # White Knight
    4: "P"   # White Pawn
    5: "Q"   # White Queen
    6: "R"   # White Rook
    7: "b"   # Black Bishop
    8: "k"   # Black King
    9: "n"   # Black Knight
    10: "p"  # Black Pawn
    11: "q"  # Black Queen
    12: "r"  # Black Rook

# Inception Detector
inception_detector:
  base_model: inception_v3
  pretrained: true
  freeze_layers: 249  # Freeze up to Mixed_7c layer
  
  # Model parameters
  input_size: [299, 299]
  num_classes: 13
  dropout: 0.5
  aux_logits: true  # Use auxiliary classifier during training
  
  # Transform settings
  transform_mode: inception  # Special inception normalization
  
  # Fine-tuning strategy
  fine_tune:
    stage1:  # Initial training
      epochs: 3
      lr: 0.001
      freeze_until: Mixed_7c
    stage2:  # Fine-tuning
      epochs: 7
      lr: 0.0001
      freeze_until: Mixed_6e
  
  # Classes (same as YOLO)
  classes:
    0: "0"
    1: "B"
    2: "K"
    3: "N"
    4: "P"
    5: "Q"
    6: "R"
    7: "b"
    8: "k"
    9: "n"
    10: "p"
    11: "q"
    12: "r"

# Model Selection
active_models:
  training: [piece_classifier, yolo_detector, inception_detector]
  inference: yolo_detector  # Default for live detection

# Ensemble Configuration
ensemble:
  enabled: false
  models: [yolo_detector, inception_detector]
  voting: weighted  # Options: weighted, majority
  weights:
    yolo_detector: 0.6
    inception_detector: 0.4

# Export Configuration
export:
  formats: [pytorch, onnx, torchscript]
  opset_version: 14  # ONNX opset
  optimize:
    quantization: false  # Dynamic quantization
    pruning: false
  
# Notes:
# - Started with yolov8n but accuracy wasn't good enough
# - Switched to yolov8s, much better results with acceptable speed
# - Confidence threshold 0.45 gave best precision/recall tradeoff
# - Inception freeze_layers=249 (Mixed_7c) provided good balance
# - aux_logits helps during training, disabled for inference
